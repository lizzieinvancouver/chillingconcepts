\documentclass[11pt]{article}
\usepackage[top=1.00in, bottom=1.0in, left=1in, right=1in]{geometry}
\renewcommand{\baselinestretch}{1.1}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{parskip}

\def\labelitemi{--}
\parindent=0pt

\begin{document}
\bibliographystyle{/Users/Lizzie/Documents/EndnoteRelated/Bibtex/styles/besjournals}
\renewcommand{\refname}{\CHead{}}

% \setlength{\parindent}{0cm}
% \setlength{\parskip}{5pt}

\emph{Lizzie working on chill refs}\\
\emph{Started 3 December 2023}

\section{What's in OSPREE?}
I feel like I must have code that pulls out interesting chill studies (I know that I have sent somebody a list of studies below 0, but I cannot find it ... in \verb|chillingnotes.txt| I pull out studies with more than one level but that will miss the updated OSPREE dataset ... So I wrote a file \verb|getchill.R| and put it in OSPREE. Then I glanced through a few of the MANY papers I found with interesting chilling treatments ... some highlights:

\begin{enumerate}
\item Cites papers that show \emph{Acer saccharum} and \emph{Juglans nigra} will not break bud for over a year without chilling.
\item Thielges 1975 shows root growth before budburst. 
\item Nienstaedt 1966 shows interaction between photoperiod and chill required for 7 \emph{Picea} species.
\item Junttila \& Hanninen: Expression of dormancy is temperature dependent. ... though not sure what they mean still. 
\item Granhus et al. 2009 -- mild spells interrupting chilling.
\item Cook et al. 2005 -- freezing temperatures and dormancy in apples.
\end{enumerate}

\section{Reviewing list of references and old notes}
I have notes in \verb|chilling_todo.txt| which reviews the current chill models (among other things). And I have notes in \verb|chillingnotes.txt| which includes discussions with Rob Guy and also Al Kovaleski. I did not check these must yet ... 

I reviewed \verb|Articles/_chillingrefs.pdf| and either pulled all articles in it, or ordered them from Harvard. I also have old notes in \verb|Articles/chillunits.txt| My notes there on Olsson \& Jonsson 2014 are especially compelling:

\begin{quote}
Olsson, Cecilia & Jönsson, Anna. (2014). Process-based models not always better than empirical models for simulating budburst of Norway spruce and birch in Europe. Global Change Biology. 20. 10.1111/gcb.12593.

Shows how interdependent the parameters are.

"The temperature differences between the calibration and evaluation data were not large enough to detect if the more complex models capture true limitations in day length or chilling."

"More complex models, representing a higher level of physiological realism, did not improve model performance, and seemed more sensitive to the calibration data."

Ahhh!!!!
\end{quote}

I also had notes there on:

Chuine, I. And Pl Cour. (1999) Climatic determinants of budburst seasonality in four temperate-zone tree species. New Phytol. 143:339-349\\
Harrington \& Gould 2015


\section{Miscellaneous}

Favorite review on chilling (Decision for GCB-15-1523 - Global Change Biology) 

However, for the following reasons, I don’t find the
argument convincing:\\
1)      The methodology is not well described. There is hardly any detail on how the
analysis was done. Important details are only presented in the supplementary materials,
and for other critical information, the reader is referred to a 21-year old publication.\\
2)      Even after looking through the supplementary materials and the 1994 paper, it
remains unclear to me, how the phenology data was converted into something that could be
used to evaluate phenology models. Some sites were apparently visited once per year
(these may have been excluded), and scoring methods differed across sites and seem to
have been rather crude. How can this provide insights into budburst dates that are
precise enough for model evaluation? It is also unclear how the various models were
compared, since the supplementary materials do not provide sufficient detail (and are
 really not self-explanatory).\\
3)      The source of temperature data is not well described, even though this is a
critical input for the analysis. Unless phenology observations were conducted in
immediate proximity of a weather station, weather station data is unlikely to accurately
reflect temperatures trees were exposed to. In some cases, they may still be useful, but
in many situations, there may be systematic differences between station and trial
climate. These can be caused by elevation differences, or general landscape
characteristics (e.g. forest vs. urban, grassland or airport setting, where most weather
stations are found). These differences can be several degrees, even for stations that are
reasonably close to a trial site, and they therefore have potential to introduce strong
bias that in my opinion cannot be ignored. It is often possible to reduce this bias
through calibration of long-term station data with short-term trial site observations,
but it doesn’t seem like this was done here.\\
4)      I have doubts about the validity of the sequential model, when comparing budburst
information across climatically different sites. This model may produce a good fit, when
used on single-site data, but it does not agree with some possible dormancy-breaking
concepts that have been put forward: a) the chilling requirement may depend on
temperature conditions during dormancy initiation (I am moderately confident that this is
the case); and b) inadequate chilling can be compensated by additional heat (quite
confident about this). Both are of relatively little importance, when looking at
single-site data, where weather may be quite similar from year to year, but they can play
a major role in explaining phenological differences between locations. Differences in
budburst responses to weather may then be caused by differences in temperature stimuli
during dormancy initiation, and by interactions between chilling and forcing
requirements. This would then not constitute an adaptive response, but a manifestation of
different features of the trees’ temperature response mechanisms that they might also
display in different locations, if the weather there were different.\\
5)      The model used does not seem to contain sensitivity to photoperiod, which is
surprising, given that many studies have shown a photoperiodic effect. I can imagine that
when testing models based on data from a single site, or several sites that are
reasonably close together, models can be quite effective, even if this is an important
factor, because daylength doesn’t vary much across years/locations. When evaluating data
across Europe, however, photosensitivity may become an important factor to consider. At
least this should be tested, rather than assuming that this effect is insignificant,
which the authors have basically done by adopting a model that doesn’t have such an
effect.\\
6)      Related to the last two points: Models aren’t perfect, so we shouldn’t be
surprised when reality differs from what models predict. We should therefore be cautious
in the interpretation of such differences as expressions of some real-world biological
phenomena. They may just as well have arisen from limitations in model validity. I’ve
compared horticultural chill models across climates, and found enormous problems with
some of the models; this is probably also the case for the forestry ones. It should also
be considered that differences in diurnal temperature ranges are quite substantial across
the sites evaluated here. For models that rely on daily means only (I believe that is
true for the models used here), this can be a problem. In horticulture, for this reason,
hourly temperatures are normally used as inputs. So I think there is a good chance that
the model used here simply is not an accurate and sufficiently general representation of
the dormancy breaking process, and that this is a likely reason for the poor fits seen
when fitting a model to all data. I don’t get the impression that the authors have
considered the possibility of flaws in their model sufficiently. Therefore, I feel that
they have overinterpreted their findings in a way that is not well substantiated by the
findings.\\
7)      I find the authors’ command of older literature on this topic remarkable, but it
seems to me that they missed some more recent findings that really question the validity
of the sequential approach. My expertise is largely limited to fruit tree phenology,

which (surprisingly) has developed its own body of literature on essentially the same
topic, but from there I am aware of several useful articles (including reviews) that have
appeared in the past 5 years or so, which cast some doubt on the general validity of the
sequential model (search phrases ‘tree dormancy review’, ‘tree dormancy initiation’ or
‘tree dormancy release’ in google scholar turn up a lot of useful recent studies).
In summary, I see too many implicit assumptions about a number of factors (temperature at
station equals trial temperature, daily temperature amplitude doesn’t matter, photoperiod
is not important, chilling and forcing occur sequentially, summer/fall temperature have
no effect on chilling requirements, chilling and forcing requirements are fixed and if
not this must be a site-specific adaptation). I find some of these highly questionable,
and I think the authors failed to discuss them as potential sources of error in their
analysis. For this reason, I am not convinced that the findings provide robust evidence
of site-specific adaptive plasticity that the authors claim.


\end{document}

